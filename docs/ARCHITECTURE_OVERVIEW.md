# Architecture Overview - Distributed PostgreSQL Cluster

**High-level system design and architectural patterns**

---

## ðŸŽ¯ Executive Summary

A production-ready distributed PostgreSQL architecture that presents as **one database** while distributing data across multiple nodes with automatic failover, load balancing, and vector operations.

**Key Characteristics:**
- **Single Endpoint:** Applications connect to one URL
- **Distributed Storage:** Data sharded across 4 workers (100GB capacity)
- **High Availability:** <10s coordinator failover, <5s worker failover
- **Horizontal Scaling:** Add workers for capacity, coordinators for redundancy
- **Zero Licensing:** 100% open source PostgreSQL

---

## ðŸ— System Architecture

### High-Level View

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Application Layer                     â”‚
â”‚         postgres://cluster:5432/distributed_postgres_cluster â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Load Balancer Layer                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  HAProxy     â”‚  â”‚  PgBouncer   â”‚  â”‚  PgBouncer   â”‚      â”‚
â”‚  â”‚  (Port 8008) â”‚  â”‚  (Port 6432) â”‚  â”‚  (Port 6432) â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Coordinator Layer (Citus)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Coordinator-1  â”‚  â”‚ Coordinator-2  â”‚  â”‚ Coordinator-3  â”‚â”‚
â”‚  â”‚ (Master)       â”‚  â”‚ (Replica)      â”‚  â”‚ (Replica)      â”‚â”‚
â”‚  â”‚ Port 5432      â”‚  â”‚ Port 5432      â”‚  â”‚ Port 5432      â”‚â”‚
â”‚  â”‚ + Patroni      â”‚  â”‚ + Patroni      â”‚  â”‚ + Patroni      â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Worker Layer (Storage)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Worker-1 â”‚  â”‚ Worker-2 â”‚  â”‚ Worker-3 â”‚  â”‚ Worker-4 â”‚   â”‚
â”‚  â”‚ 25GB     â”‚  â”‚ 25GB     â”‚  â”‚ 25GB     â”‚  â”‚ 25GB     â”‚   â”‚
â”‚  â”‚ Port 5432â”‚  â”‚ Port 5432â”‚  â”‚ Port 5432â”‚  â”‚ Port 5432â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                    Total Capacity: 100GB                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Consensus Layer (etcd)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  etcd-1   â”‚      â”‚  etcd-2   â”‚      â”‚  etcd-3   â”‚       â”‚
â”‚  â”‚ Port 2379 â”‚      â”‚ Port 2379 â”‚      â”‚ Port 2379 â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Monitoring Layer                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Prometheus   â”‚  â”‚  Grafana     â”‚  â”‚  Alertmanagerâ”‚      â”‚
â”‚  â”‚ Port 9090    â”‚  â”‚  Port 3000   â”‚  â”‚  Port 9093   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”„ Request Flow

### Write Request Flow

```
1. Application â†’ HAProxy:8008
   "INSERT INTO users VALUES (...)"

2. HAProxy â†’ PgBouncer (coordinator-1):6432
   Routes to master coordinator

3. PgBouncer â†’ Coordinator-1:5432
   Connection pooling (reuse existing connection)

4. Coordinator-1 â†’ Query Planner
   "Which shard(s) need this data?"
   Determines worker based on distribution column

5. Coordinator-1 â†’ Worker-2:5432
   Sends write to appropriate worker

6. Worker-2 â†’ Disk
   Writes data to storage

7. Worker-2 â†’ Coordinator-1
   ACK write completed

8. Coordinator-1 â†’ PgBouncer
   Return success to client

9. PgBouncer â†’ HAProxy â†’ Application
   "INSERT 1"
```

### Read Request Flow

```
1. Application â†’ HAProxy:8008
   "SELECT * FROM users WHERE tenant_id = 123"

2. HAProxy â†’ PgBouncer (any coordinator):6432
   Can route to master or replica

3. PgBouncer â†’ Coordinator-2:5432 (replica)
   Connection pooling

4. Coordinator-2 â†’ Query Planner
   "Which shard(s) have tenant_id = 123?"
   Looks up metadata

5. Coordinator-2 â†’ Worker-3:5432
   Sends query to specific worker(s)

6. Worker-3 â†’ Coordinator-2
   Returns result rows

7. Coordinator-2 â†’ PgBouncer
   Returns combined results

8. PgBouncer â†’ HAProxy â†’ Application
   Result set
```

### Vector Search Request Flow

```
1. Application â†’ HAProxy:8008
   "SELECT * FROM vectors WHERE embedding <=> $1 ORDER BY ... LIMIT 10"

2. HAProxy â†’ PgBouncer â†’ Coordinator-1:5432

3. Coordinator-1 â†’ Query Planner
   Distributed HNSW index lookup
   Determines which workers to query

4. Coordinator-1 â†’ [Worker-1, Worker-2, Worker-3, Worker-4]
   Parallel queries to all workers with HNSW indexes

5. Workers â†’ HNSW Index Search
   Each worker searches local HNSW index
   Returns top-k candidates

6. Workers â†’ Coordinator-1
   Return local top-k results

7. Coordinator-1 â†’ Merge Results
   Combines results from all workers
   Re-ranks and returns global top-10

8. Coordinator-1 â†’ Application
   Final top-10 results
```

---

## ðŸ§© Component Architecture

### 1. Load Balancer Layer

#### HAProxy
- **Role:** L4 load balancer
- **Port:** 8008 (external), forwards to 5432 (PostgreSQL)
- **Features:**
  - Health checks every 2 seconds
  - Automatic backend failure detection
  - Round-robin load balancing
  - Master/replica routing
  - Connection limiting

#### PgBouncer
- **Role:** Connection pooler
- **Port:** 6432 (external), connects to 5432 (PostgreSQL)
- **Features:**
  - Connection reuse (session pooling)
  - Max 100 connections per pool
  - Query routing to master/replica
  - Connection queue management
  - Reduced PostgreSQL overhead

```
Connection Math:
- 1000 application connections â†’ HAProxy
- HAProxy â†’ 3 PgBouncer instances
- Each PgBouncer â†’ 100 PostgreSQL connections (max)
- Total PostgreSQL connections: 300 (instead of 1000)
```

### 2. Coordinator Layer (Citus)

#### Citus Extension
- **Role:** Distributed query processing
- **Key Functions:**
  - Sharding metadata management
  - Query planning and routing
  - Distributed transaction coordination
  - Result aggregation
  - Worker health monitoring

#### Patroni
- **Role:** High availability and failover
- **Key Functions:**
  - Leader election (via etcd)
  - Automatic failover (<10s)
  - Configuration management
  - Replication monitoring
  - Backup coordination

```
Failover Scenario:
1. Coordinator-1 (master) fails
2. Patroni detects failure (5s heartbeat timeout)
3. etcd consensus initiates leader election
4. Coordinator-2 promoted to master (2-3s)
5. HAProxy detects new master (2s health check)
6. Total downtime: ~10s
```

### 3. Worker Layer

#### PostgreSQL Workers
- **Role:** Data storage and computation
- **Configuration:**
  - 4 workers Ã— 25GB = 100GB total capacity
  - Each worker: 2 CPU, 4GB RAM (configurable)
  - RuVector 2.0 extension installed
  - HNSW indexes for vector search

#### Sharding Strategy
```sql
-- Hash-based sharding on distribution column
SELECT create_distributed_table('users', 'tenant_id');

-- Result: Data distributed across workers
-- tenant_id % 4 determines worker placement
-- Worker-1: tenant_ids ending in 0 (0, 4, 8, ...)
-- Worker-2: tenant_ids ending in 1 (1, 5, 9, ...)
-- Worker-3: tenant_ids ending in 2 (2, 6, 10, ...)
-- Worker-4: tenant_ids ending in 3 (3, 7, 11, ...)
```

### 4. Consensus Layer (etcd)

#### etcd Cluster
- **Role:** Distributed configuration and leader election
- **Configuration:**
  - 3-node cluster (quorum requires 2 of 3)
  - Raft consensus protocol
  - Stores Patroni cluster state
  - Monitors coordinator health

```
etcd Key-Value Store:
/patroni/postgres-cluster/
  â”œâ”€â”€ config (cluster configuration)
  â”œâ”€â”€ leader (current master)
  â”œâ”€â”€ members/
  â”‚   â”œâ”€â”€ coordinator-1 (health, role)
  â”‚   â”œâ”€â”€ coordinator-2 (health, role)
  â”‚   â””â”€â”€ coordinator-3 (health, role)
  â””â”€â”€ history (failover history)
```

### 5. Monitoring Layer

#### Prometheus
- **Role:** Metrics collection and storage
- **Metrics:**
  - PostgreSQL: connections, queries, replication lag
  - Citus: shard distribution, worker health
  - Patroni: cluster state, failover events
  - System: CPU, memory, disk, network

#### Grafana
- **Role:** Visualization and dashboards
- **Dashboards:**
  - PostgreSQL Overview
  - Citus Distributed Metrics
  - Patroni HA Status
  - Connection Pool Metrics
  - System Resources

---

## ðŸ“Š Data Distribution

### Sharding Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Distributed Table                    â”‚
â”‚                   (Logical View)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  users (tenant_id, name, email, created_at)    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚              â”‚              â”‚
         â–¼              â–¼              â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Shard 1  â”‚   â”‚ Shard 2  â”‚   â”‚ Shard N  â”‚
  â”‚ (range)  â”‚   â”‚ (range)  â”‚   â”‚ (range)  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚              â”‚
       â–¼              â–¼              â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Worker-1 â”‚   â”‚ Worker-2 â”‚   â”‚ Worker-N â”‚
  â”‚ (storage)â”‚   â”‚ (storage)â”‚   â”‚ (storage)â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Replication Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Coordinator Replication                 â”‚
â”‚                  (Streaming Replication)             â”‚
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚Coordinator-1 â”‚â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚Coordinator-2 â”‚          â”‚
â”‚  â”‚  (Master)    â”‚         â”‚  (Replica)   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚            â”‚                               â”‚
â”‚         â”‚            â””â”€â”€â”€â†’â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚         â”‚                 â”‚Coordinator-3 â”‚          â”‚
â”‚         â”‚                 â”‚  (Replica)   â”‚          â”‚
â”‚         â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                                             â”‚
â”‚         â””â”€â”€â”€â”€â†’ Only metadata replicated               â”‚
â”‚                (Citus metadata tables)                â”‚
â”‚                                                       â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚         â”‚  Shards NOT replicated between  â”‚          â”‚
â”‚         â”‚  workers (use Patroni for HA)   â”‚          â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ” Security Architecture

### Network Security

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Security Layers                     â”‚
â”‚                                                       â”‚
â”‚  Internet/WAN                                        â”‚
â”‚       â†“                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Firewall (iptables/ufw)                â”‚        â”‚
â”‚  â”‚  - Allow 8008 (HAProxy)                 â”‚        â”‚
â”‚  â”‚  - Deny direct PostgreSQL (5432)        â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚       â†“                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  TLS/SSL Layer                          â”‚        â”‚
â”‚  â”‚  - Certificate validation               â”‚        â”‚
â”‚  â”‚  - Encrypted connections                â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚       â†“                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  HAProxy                                â”‚        â”‚
â”‚  â”‚  - Rate limiting                        â”‚        â”‚
â”‚  â”‚  - Connection limits                    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚       â†“                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  PostgreSQL Authentication              â”‚        â”‚
â”‚  â”‚  - Password (scram-sha-256)             â”‚        â”‚
â”‚  â”‚  - SSL certificates                     â”‚        â”‚
â”‚  â”‚  - pg_hba.conf rules                    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚       â†“                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Application Layer                      â”‚        â”‚
â”‚  â”‚  - Input validation                     â”‚        â”‚
â”‚  â”‚  - Parameterized queries                â”‚        â”‚
â”‚  â”‚  - SQL injection prevention             â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Access Control

```
Users & Roles:
â”œâ”€â”€ superuser (postgres)
â”‚   â””â”€â”€ Full cluster administration
â”œâ”€â”€ dpg_cluster (application owner)
â”‚   â”œâ”€â”€ Create/drop databases
â”‚   â”œâ”€â”€ Create/modify tables
â”‚   â””â”€â”€ Grant permissions
â”œâ”€â”€ app_readonly
â”‚   â””â”€â”€ SELECT on all tables
â””â”€â”€ app_readwrite
    â”œâ”€â”€ SELECT, INSERT, UPDATE, DELETE
    â””â”€â”€ No DDL operations
```

---

## ðŸš€ Scalability Patterns

### Horizontal Scaling (Add Workers)

```
Current: 4 workers Ã— 25GB = 100GB capacity

Scale to: 8 workers Ã— 25GB = 200GB capacity

Steps:
1. Deploy new workers (worker-5, worker-6, worker-7, worker-8)
2. Register workers with coordinator:
   SELECT citus_add_node('worker-5', 5432)
3. Rebalance shards:
   SELECT rebalance_table_shards('users')
4. Monitor rebalancing progress
5. Verify shard distribution

Downtime: 0 (online operation)
Duration: ~1-2 hours for data rebalancing
```

### Vertical Scaling (Increase Resources)

```
Current: 2 CPU, 4GB RAM per node

Scale to: 4 CPU, 8GB RAM per node

Steps:
1. Rolling restart with new resource limits
2. Update Docker service:
   docker service update --limit-cpu 4 --limit-memory 8g worker-1
3. Repeat for each worker
4. Monitor performance improvement

Downtime: 0 (rolling restart)
Duration: ~30 minutes
```

### Read Scaling (Add Replicas)

```
Add coordinator replicas for read scaling:

Current: 1 master + 2 replicas = 3 coordinators

Scale to: 1 master + 4 replicas = 5 coordinators

Steps:
1. Deploy new coordinator nodes
2. Patroni automatically replicates metadata
3. Configure HAProxy to include new replicas
4. Route read queries to replicas

Downtime: 0
Duration: ~10 minutes
```

---

## ðŸ“ˆ Performance Characteristics

### Latency Profile

```
Operation           | p50    | p95    | p99    | Target
--------------------|--------|--------|--------|---------
Simple SELECT       | 2ms    | 5ms    | 8ms    | <10ms
Distributed SELECT  | 5ms    | 12ms   | 18ms   | <20ms
INSERT              | 3ms    | 8ms    | 12ms   | <15ms
Vector search (k=10)| 8ms    | 15ms   | 25ms   | <30ms
```

### Throughput Targets

```
Workload               | Target     | Achieved
-----------------------|------------|----------
Simple queries         | 10,000 TPS | TBD
Distributed queries    | 5,000 TPS  | TBD
Vector searches        | 1,000 QPS  | TBD
Concurrent connections | 1,000      | TBD
```

### Scaling Limits

```
Dimension              | Limit          | Reason
-----------------------|----------------|------------------------
Max workers            | 32             | Citus coordinator limit
Max coordinators       | 10             | Diminishing returns
Max connections/worker | 100            | PostgreSQL config
Max database size      | 800GB (32Ã—25GB)| Worker capacity
Max shard count        | 128            | Optimal balance
```

---

## ðŸ”„ Deployment Topologies

### Development (Single Node)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Single Docker Host    â”‚
â”‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ All-in-one Container â”‚  â”‚
â”‚  â”‚ - Coordinator        â”‚  â”‚
â”‚  â”‚ - Worker (1)         â”‚  â”‚
â”‚  â”‚ - HAProxy            â”‚  â”‚
â”‚  â”‚ - PgBouncer          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Resources: 4GB RAM, 2 CPU
Use case: Development, testing
```

### Production (Docker Swarm)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Docker Swarm Cluster              â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  Manager-1  â”‚  â”‚  Manager-2  â”‚         â”‚
â”‚  â”‚  + etcd     â”‚  â”‚  + etcd     â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  Worker-1   â”‚  â”‚  Worker-2   â”‚         â”‚
â”‚  â”‚  + Coord    â”‚  â”‚  + Coord    â”‚         â”‚
â”‚  â”‚  + PgBouncerâ”‚  â”‚  + PgBouncerâ”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  Worker-3   â”‚  â”‚  Worker-4   â”‚         â”‚
â”‚  â”‚  + Storage  â”‚  â”‚  + Storage  â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Resources: 32GB RAM, 16 CPU total
Use case: Production, high availability
```

### Enterprise (Kubernetes)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Kubernetes Cluster                   â”‚
â”‚                                             â”‚
â”‚  Namespace: postgres-cluster                â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  StatefulSet: coordinators   â”‚          â”‚
â”‚  â”‚  - Replicas: 3               â”‚          â”‚
â”‚  â”‚  - PVC: 50GB each            â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  StatefulSet: workers        â”‚          â”‚
â”‚  â”‚  - Replicas: 4               â”‚          â”‚
â”‚  â”‚  - PVC: 100GB each           â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  Deployment: pgbouncer       â”‚          â”‚
â”‚  â”‚  - Replicas: 3               â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  Service: LoadBalancer       â”‚          â”‚
â”‚  â”‚  - External IP               â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Resources: Autoscaling
Use case: Enterprise, cloud-native
```

---

## ðŸ§  Design Patterns

### 1. Command Query Responsibility Segregation (CQRS)

```
Write Path (Commands):
Application â†’ HAProxy â†’ Master Coordinator â†’ Workers

Read Path (Queries):
Application â†’ HAProxy â†’ Replica Coordinator â†’ Workers

Benefits:
- Read scaling independent of writes
- Reduced load on master
- Optimized read replicas
```

### 2. Circuit Breaker

```
HAProxy health checks:
- Check interval: 2 seconds
- Failure threshold: 3 consecutive failures
- Recovery: Automatic when health restored

Behavior:
- Working backend: Route traffic
- Failed backend: Stop routing (circuit open)
- Recovered backend: Resume routing (circuit closed)
```

### 3. Connection Pooling

```
Application (1000 connections)
         â†“
PgBouncer (pools to 100 connections)
         â†“
PostgreSQL (100 actual connections)

Benefits:
- Reduced PostgreSQL overhead
- Faster connection reuse
- Better resource utilization
```

### 4. Saga Pattern (Distributed Transactions)

```
For multi-shard transactions:
1. Begin distributed transaction
2. Execute on each shard
3. Prepare to commit (2PC)
4. Commit or rollback all shards

Citus handles:
- Two-phase commit protocol
- Coordinator-worker coordination
- Rollback on any failure
```

---

## ðŸ” Observability

### Metrics Collection

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Metrics Pipeline                 â”‚
â”‚                                          â”‚
â”‚  PostgreSQL Exporters                   â”‚
â”‚         â†“                                â”‚
â”‚  Prometheus (scrape every 15s)          â”‚
â”‚         â†“                                â”‚
â”‚  Grafana (visualization)                â”‚
â”‚         â†“                                â”‚
â”‚  Alertmanager (alerts)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Key Metrics:
- pg_up: Database availability
- pg_stat_database_numbackends: Active connections
- pg_stat_replication_lag_seconds: Replication lag
- citus_shard_count: Shard distribution
- patroni_master: Current master
```

### Logging Architecture

```
Components:
â”œâ”€â”€ PostgreSQL logs â†’ /var/log/postgresql/
â”œâ”€â”€ Patroni logs â†’ journald
â”œâ”€â”€ HAProxy logs â†’ /var/log/haproxy.log
â”œâ”€â”€ PgBouncer logs â†’ /var/log/pgbouncer/
â””â”€â”€ Application logs â†’ stdout (Docker)

Aggregation:
- Collect via Fluentd/Filebeat
- Store in Elasticsearch
- Visualize in Kibana
```

---

## ðŸ“š Further Reading

### Deep Dives
- **[Distributed Design](architecture/distributed-postgres-design.md)** - Complete architecture details
- **[Patroni HA Design](architecture/PATRONI_HA_DESIGN.md)** - High availability deep dive
- **[DDD Domain Architecture](architecture/DDD_DOMAIN_ARCHITECTURE.md)** - Domain boundaries

### Operations
- **[Operations Guide](OPERATIONS_GUIDE.md)** - Daily operations
- **[Scaling Playbook](operations/SCALING_PLAYBOOK.md)** - Scaling procedures
- **[Failover Runbook](operations/FAILOVER_RUNBOOK.md)** - Failover handling

### Implementation
- **[Quick Start](QUICK_START.md)** - Deploy in 5 minutes
- **[Production Deployment](architecture/PRODUCTION_DEPLOYMENT.md)** - Production setup
- **[Monitoring Setup](MONITORING.md)** - Monitoring configuration

---

**Last Updated:** 2026-02-12

*For questions, see [Documentation Index](README.md)*
