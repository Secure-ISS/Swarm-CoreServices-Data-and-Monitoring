name: CI/CD Full Stack Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '20'

jobs:
  # ============================================================================
  # STAGE 1: CODE QUALITY & SECURITY
  # ============================================================================
  code-quality:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Run Black formatter check
        run: black --check src/ tests/

      - name: Run isort import check
        run: isort --check-only src/ tests/

      - name: Run flake8 linter
        run: flake8 src/ tests/ --max-line-length=120

      - name: Run pylint
        run: pylint src/ --fail-under=8.0

      - name: Run mypy type checking
        run: mypy src/ --ignore-missing-imports

  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'

      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'trivy-results.sarif'

      - name: Run Snyk security scan
        uses: snyk/actions/python@master
        continue-on-error: true
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          command: test
          args: --severity-threshold=high

      - name: Run Bandit security linter
        run: |
          pip install bandit
          bandit -r src/ -f json -o bandit-report.json || true

      - name: Upload security reports
        uses: actions/upload-artifact@v4
        with:
          name: security-reports
          path: |
            trivy-results.sarif
            bandit-report.json

  # ============================================================================
  # STAGE 2: UNIT & INTEGRATION TESTS
  # ============================================================================
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12']
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Run unit tests with coverage
        run: |
          pytest tests/unit/ \
            --cov=src \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term \
            --junitxml=junit.xml \
            -v

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage.xml
          flags: unit-tests
          name: unit-${{ matrix.python-version }}
          token: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-unit-${{ matrix.python-version }}
          path: |
            junit.xml
            htmlcov/

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    services:
      postgres:
        image: ruvnet/ruvector-postgres:latest
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: test_db
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Wait for services
        run: |
          timeout 60 bash -c 'until pg_isready -h localhost -p 5432; do sleep 1; done'
          timeout 60 bash -c 'until redis-cli -h localhost ping; do sleep 1; done'

      - name: Initialize database
        env:
          DATABASE_URL: postgresql://postgres:test_password@localhost:5432/test_db
        run: |
          python scripts/init_database.py

      - name: Run integration tests
        env:
          DATABASE_URL: postgresql://postgres:test_password@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379
        run: |
          pytest tests/integration/ \
            --cov=src \
            --cov-report=xml \
            --junitxml=junit-integration.xml \
            -v

      - name: Upload coverage
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage.xml
          flags: integration-tests
          token: ${{ secrets.CODECOV_TOKEN }}

  # ============================================================================
  # STAGE 3: E2E & PERFORMANCE TESTS
  # ============================================================================
  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Start test environment
        run: |
          docker-compose -f docker-compose.test.yml up -d
          sleep 30

      - name: Wait for services
        run: |
          timeout 120 bash -c 'until curl -f http://localhost:8000/health; do sleep 2; done'

      - name: Run E2E tests
        run: |
          docker-compose -f docker-compose.test.yml exec -T api \
            pytest tests/e2e/ -v --junitxml=junit-e2e.xml

      - name: Collect logs
        if: always()
        run: |
          docker-compose -f docker-compose.test.yml logs > e2e-logs.txt

      - name: Cleanup
        if: always()
        run: docker-compose -f docker-compose.test.yml down -v

      - name: Upload E2E artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-artifacts
          path: |
            junit-e2e.xml
            e2e-logs.txt

  performance-tests:
    name: Performance Regression Tests
    runs-on: ubuntu-latest
    needs: [integration-tests]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install locust pytest-benchmark

      - name: Start services
        run: |
          docker-compose -f docker-compose.test.yml up -d postgres redis
          sleep 20

      - name: Run performance benchmarks
        run: |
          pytest tests/performance/ \
            --benchmark-only \
            --benchmark-json=benchmark.json \
            --benchmark-compare-fail=mean:10%

      - name: Run load tests
        run: |
          locust -f tests/performance/locustfile.py \
            --headless \
            --users 100 \
            --spawn-rate 10 \
            --run-time 2m \
            --host http://localhost:8000 \
            --html=locust-report.html

      - name: Check performance regression
        run: |
          python scripts/ci/check_performance_regression.py \
            --current benchmark.json \
            --baseline performance-baseline.json \
            --threshold 10

      - name: Upload performance reports
        uses: actions/upload-artifact@v4
        with:
          name: performance-reports
          path: |
            benchmark.json
            locust-report.html

  # ============================================================================
  # STAGE 4: BUILD & PUSH DOCKER IMAGES
  # ============================================================================
  build-images:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: [code-quality, security-scan, unit-tests, integration-tests]
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
    permissions:
      contents: read
      packages: write
    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      image-digest: ${{ steps.build.outputs.digest }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push API image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/Dockerfile.api
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache
          cache-to: type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache,mode=max
          build-args: |
            VERSION=${{ github.sha }}
            BUILD_DATE=${{ github.event.head_commit.timestamp }}

      - name: Run Trivy on Docker image
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
          format: 'sarif'
          output: 'trivy-image-results.sarif'

      - name: Upload Trivy results
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'trivy-image-results.sarif'

  # ============================================================================
  # STAGE 5: DEPLOY TO STAGING
  # ============================================================================
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [build-images, e2e-tests, performance-tests]
    if: github.ref == 'refs/heads/develop' || github.event.inputs.environment == 'staging'
    environment:
      name: staging
      url: https://staging.dpg-cluster.example.com
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-west-2

      - name: Deploy to ECS (Staging)
        run: |
          # Update ECS task definition
          aws ecs register-task-definition \
            --cli-input-json file://ecs-task-definition-staging.json

          # Update ECS service
          aws ecs update-service \
            --cluster dpg-cluster-staging \
            --service dpg-api-staging \
            --task-definition dpg-api-staging:latest \
            --force-new-deployment

      - name: Wait for deployment
        run: |
          aws ecs wait services-stable \
            --cluster dpg-cluster-staging \
            --services dpg-api-staging

      - name: Run smoke tests
        run: |
          python scripts/ci/smoke_tests.py \
            --url https://staging.dpg-cluster.example.com \
            --timeout 300

      - name: Rollback on failure
        if: failure()
        run: |
          # Get previous task definition
          PREVIOUS_TASK=$(aws ecs describe-services \
            --cluster dpg-cluster-staging \
            --services dpg-api-staging \
            --query 'services[0].taskDefinition' \
            --output text | sed 's/:latest//')

          # Rollback
          aws ecs update-service \
            --cluster dpg-cluster-staging \
            --service dpg-api-staging \
            --task-definition $PREVIOUS_TASK

  # ============================================================================
  # STAGE 6: DEPLOY TO PRODUCTION (MANUAL APPROVAL)
  # ============================================================================
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [deploy-staging]
    if: github.ref == 'refs/heads/main' || github.event.inputs.environment == 'production'
    environment:
      name: production
      url: https://dpg-cluster.example.com
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-west-2

      - name: Blue-Green Deployment
        run: |
          # Get current target group
          CURRENT_TG=$(aws elbv2 describe-target-groups \
            --names dpg-production-blue \
            --query 'TargetGroups[0].TargetGroupArn' \
            --output text)

          # Determine new target group
          if [[ "$CURRENT_TG" == *"blue"* ]]; then
            NEW_TG="dpg-production-green"
            OLD_TG="dpg-production-blue"
          else
            NEW_TG="dpg-production-blue"
            OLD_TG="dpg-production-green"
          fi

          # Deploy to new target group
          aws ecs update-service \
            --cluster dpg-cluster-production \
            --service dpg-api-$NEW_TG \
            --task-definition dpg-api-production:latest \
            --force-new-deployment

          # Wait for new service
          aws ecs wait services-stable \
            --cluster dpg-cluster-production \
            --services dpg-api-$NEW_TG

          # Switch traffic
          aws elbv2 modify-listener \
            --listener-arn ${{ secrets.ALB_LISTENER_ARN }} \
            --default-actions Type=forward,TargetGroupArn=$NEW_TG

          # Wait and drain old target group
          sleep 60
          aws ecs update-service \
            --cluster dpg-cluster-production \
            --service dpg-api-$OLD_TG \
            --desired-count 0

      - name: Run production smoke tests
        run: |
          python scripts/ci/smoke_tests.py \
            --url https://dpg-cluster.example.com \
            --timeout 300 \
            --critical

      - name: Rollback on failure
        if: failure()
        run: |
          # Immediate rollback
          bash scripts/ci/rollback-production.sh

      - name: Create GitHub release
        if: success() && github.ref == 'refs/heads/main'
        uses: actions/create-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tag_name: v${{ github.run_number }}
          release_name: Release v${{ github.run_number }}
          body: |
            Automated production deployment
            Commit: ${{ github.sha }}
            Deployed: ${{ github.event.head_commit.timestamp }}
          draft: false
          prerelease: false

  # ============================================================================
  # NOTIFICATIONS
  # ============================================================================
  notify:
    name: Send Notifications
    runs-on: ubuntu-latest
    needs: [deploy-production]
    if: always()
    steps:
      - name: Send Slack notification
        uses: slackapi/slack-github-action@v1
        with:
          webhook-url: ${{ secrets.SLACK_WEBHOOK_URL }}
          payload: |
            {
              "text": "Deployment ${{ job.status }}",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Deployment Status:* ${{ job.status }}\n*Environment:* Production\n*Commit:* ${{ github.sha }}"
                  }
                }
              ]
            }
